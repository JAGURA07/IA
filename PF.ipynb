{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2bmayhDAhKPDWK2Awsnzh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"id":"WuB1tkFtKUwN","executionInfo":{"status":"ok","timestamp":1675140930914,"user_tz":360,"elapsed":9,"user":{"displayName":"JAGURA","userId":"01920608359559747946"}}},"outputs":[],"source":["class Organism():\n","    def __init__(self, dimensions, use_bias=True, output='softmax'):\n","        self.layers = []\n","        self.biases = []\n","        self.use_bias = use_bias\n","        self.output = self._activation(output)\n","        for i in range(len(dimensions)-1):\n","            shape = (dimensions[i], dimensions[i+1])\n","            std = np.sqrt(2 / sum(shape))\n","            layer = np.random.normal(0, std, shape)\n","            bias = np.random.normal(0, std, (1,  dimensions[i+1])) * use_bias\n","            self.layers.append(layer)\n","            self.biases.append(bias)\n","\n","    def _activation(self, output):\n","        if output == 'softmax':\n","            return lambda X : np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1, 1)\n","        if output == 'sigmoid':\n","            return lambda X : (1 / (1 + np.exp(-X)))\n","        if output == 'linear':\n","            return lambda X : X\n","\n","    def predict(self, X):\n","        if not X.ndim == 2:\n","            raise ValueError(f'Input has {X.ndim} dimensions, expected 2')\n","        if not X.shape[1] == self.layers[0].shape[0]:\n","            raise ValueError(f'Input has {X.shape[1]} features, expected {self.layers[0].shape[0]}')\n","        for index, (layer, bias) in enumerate(zip(self.layers, self.biases)):\n","            X = X @ layer + np.ones((X.shape[0], 1)) @ bias\n","            if index == len(self.layers) - 1:\n","                X = self.output(X) # output activation\n","            else:\n","                X = np.clip(X, 0, np.inf)  # ReLU\n","        return X"]},{"cell_type":"code","source":["class Ecosystem():\n","    # [Some code removed here]\n","    \n","    def generation(self, repeats=1, keep_best=True):\n","        rewards = rewards = [np.mean([self.scoring_function(x) for _ in range(repeats)]) for x in self.population]\n","        self.population = [self.population[x] for x in np.argsort(rewards)[::-1]]\n","        new_population = []\n","        for i in range(self.population_size):\n","            parent_1_idx = i % self.holdout\n","            if self.mating:\n","                parent_2_idx = min(self.population_size - 1, int(np.random.exponential(self.holdout)))\n","            else:\n","                parent_2_idx = parent_1_idx\n","            offspring = self.population[parent_1_idx].mate(self.population[parent_2_idx])\n","            new_population.append(offspring)\n","        if keep_best:\n","            new_population[-1] = self.population[0] # Ensure best organism survives\n","        self.population = new_population"],"metadata":{"id":"X4ZRqNIyK5c7","executionInfo":{"status":"ok","timestamp":1675140930914,"user_tz":360,"elapsed":9,"user":{"displayName":"JAGURA","userId":"01920608359559747946"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class Organism():\n","    # [Some code removed here]\n","\n","    def mate(self, other, mutate=True):\n","        if self.use_bias != other.use_bias:\n","            raise ValueError('Both parents must use bias or not use bias')\n","        if not len(self.layers) == len(other.layers):\n","            raise ValueError('Both parents must have same number of layers')\n","        if not all(self.layers[x].shape == other.layers[x].shape for x in range(len(self.layers))):\n","            raise ValueError('Both parents must have same shape')\n","\n","        child = copy.deepcopy(self)\n","        for i in range(len(child.layers)):\n","            pass_on = np.random.rand(1, child.layers[i].shape[1]) < 0.5\n","            child.layers[i] = pass_on * self.layers[i] + ~pass_on * other.layers[i]\n","            child.biases[i] = pass_on * self.biases[i] + ~pass_on * other.biases[i]\n","        if mutate:\n","            child.mutate()\n","        return child"],"metadata":{"id":"Y9j07K3WK5gJ","executionInfo":{"status":"ok","timestamp":1675140930914,"user_tz":360,"elapsed":8,"user":{"displayName":"JAGURA","userId":"01920608359559747946"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class Organism():\n","    # [Some code removed here]\n","    \n","    def mutate(self, stdev=0.03):\n","        for i in range(len(self.layers)):\n","            self.layers[i] += np.random.normal(0, stdev, self.layers[i].shape)\n","            if self.use_bias:\n","                self.biases[i] += np.random.normal(0, stdev, self.biases[i].shape)"],"metadata":{"id":"kmtVTexMK5ip","executionInfo":{"status":"ok","timestamp":1675140931067,"user_tz":360,"elapsed":161,"user":{"displayName":"JAGURA","userId":"01920608359559747946"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import copy\n","\n","import numpy as np\n","\n","class Organism():\n","    def __init__(self, dimensions, use_bias=True, output='softmax'):\n","        self.layers = []\n","        self.biases = []\n","        self.use_bias = use_bias\n","        self.output = self._activation(output)\n","        for i in range(len(dimensions)-1):\n","            shape = (dimensions[i], dimensions[i+1])\n","            std = np.sqrt(2 / sum(shape))\n","            layer = np.random.normal(0, std, shape)\n","            bias = np.random.normal(0, std, (1,  dimensions[i+1])) * use_bias\n","            self.layers.append(layer)\n","            self.biases.append(bias)\n","\n","    def _activation(self, output):\n","        if output == 'softmax':\n","            return lambda X : np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1, 1)\n","        if output == 'sigmoid':\n","            return lambda X : (1 / (1 + np.exp(-X)))\n","        if output == 'linear':\n","            return lambda X : X\n","\n","    def predict(self, X):\n","        if not X.ndim == 2:\n","            raise ValueError(f'Input has {X.ndim} dimensions, expected 2')\n","        if not X.shape[1] == self.layers[0].shape[0]:\n","            raise ValueError(f'Input has {X.shape[1]} features, expected {self.layers[0].shape[0]}')\n","        for index, (layer, bias) in enumerate(zip(self.layers, self.biases)):\n","            X = X @ layer + np.ones((X.shape[0], 1)) @ bias\n","            if index == len(self.layers) - 1:\n","                X = self.output(X) # output activation\n","            else:\n","                X = np.clip(X, 0, np.inf)  # ReLU\n","        \n","        return X\n","\n","    def predict_choice(self, X, deterministic=True):\n","        probabilities = self.predict(X)\n","        if deterministic:\n","            return np.argmax(probabilities, axis=1).reshape((-1, 1))\n","        if any(np.sum(probabilities, axis=1) != 1):\n","            raise ValueError(f'Output values must sum to 1 to use deterministic=False')\n","        if any(probabilities < 0):\n","            raise ValueError(f'Output values cannot be negative to use deterministic=False')\n","        choices = np.zeros(X.shape[0])\n","        for i in range(X.shape[0]):\n","            U = np.random.rand(X.shape[0])\n","            c = 0\n","            while U > probabilities[i, c]:\n","                U -= probabilities[i, c]\n","                c += 1\n","            else:\n","                choices[i] = c\n","        return choices.reshape((-1,1))\n","\n","    def mutate(self, stdev=0.03):\n","        for i in range(len(self.layers)):\n","            self.layers[i] += np.random.normal(0, stdev, self.layers[i].shape)\n","            if self.use_bias:\n","                self.biases[i] += np.random.normal(0, stdev, self.biases[i].shape)\n","\n","    def mate(self, other, mutate=True):\n","        if self.use_bias != other.use_bias:\n","            raise ValueError('Both parents must use bias or not use bias')\n","        if not len(self.layers) == len(other.layers):\n","            raise ValueError('Both parents must have same number of layers')\n","        if not all(self.layers[x].shape == other.layers[x].shape for x in range(len(self.layers))):\n","            raise ValueError('Both parents must have same shape')\n","\n","        child = copy.deepcopy(self)\n","        for i in range(len(child.layers)):\n","            pass_on = np.random.rand(1, child.layers[i].shape[1]) < 0.5\n","            child.layers[i] = pass_on * self.layers[i] + ~pass_on * other.layers[i]\n","            child.biases[i] = pass_on * self.biases[i] + ~pass_on * other.biases[i]\n","        if mutate:\n","            child.mutate()\n","        return child\n","\n","\n","class Ecosystem():\n","    def __init__(self, original_f, scoring_function, population_size=100, holdout='sqrt', mating=True):\n","        \"\"\"\n","        original_f must be a function to produce Organisms, used for the original population\n","        scoring_function must be a function which accepts an Organism as input and returns a float\n","        \"\"\"\n","        self.population_size = population_size=100\n","        self.population = [original_f() for _ in range(population_size)]\n","        self.scoring_function = scoring_function\n","        if holdout == 'sqrt':\n","            self.holdout = max(1, int(np.sqrt(population_size)))\n","        elif holdout == 'log':\n","            self.holdout = max(1, int(np.log(population_size)))\n","        elif holdout > 0 and holdout < 1:\n","            self.holdout = max(1, int(holdout * population_size))\n","        else:\n","            self.holdout = max(1, int(holdout))\n","        self.mating = True\n","\n","    def generation(self, repeats=1, keep_best=True):\n","        rewards = [np.mean([self.scoring_function(x) for _ in range(repeats)]) for x in self.population]\n","        self.population = [self.population[x] for x in np.argsort(rewards)[::-1]]\n","        new_population = []\n","        for i in range(self.population_size):\n","            parent_1_idx = i % self.holdout\n","            if self.mating:\n","                parent_2_idx = min(self.population_size - 1, int(np.random.exponential(self.holdout)))\n","            else:\n","                parent_2_idx = parent_1_idx\n","            offspring = self.population[parent_1_idx].mate(self.population[parent_2_idx])\n","            new_population.append(offspring)\n","        if keep_best:\n","            new_population[-1] = self.population[0] # Ensure best organism survives\n","        self.population = new_population\n","\n","    def get_best_organism(self, repeats=1, include_reward=False):\n","        rewards = [np.mean(self.scoring_function(x)) for _ in range(repeats) for x in self.population]\n","        if include_reward:\n","            best = np.argsort(rewards)[-1]\n","            return self.population[best], rewards[best]\n","        else:\n","            return self.population[np.argsort(rewards)[-1]]"],"metadata":{"id":"jUhcujE2K5lh","executionInfo":{"status":"ok","timestamp":1675140931067,"user_tz":360,"elapsed":4,"user":{"displayName":"JAGURA","userId":"01920608359559747946"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# The function to create the initial population\n","organism_creator = lambda : Organism([1, 16, 16, 16, 1], output='linear')\n","# The function we are trying to learn. numpy doesn't have tau...\n","true_function = lambda x : np.sin(2 * np.pi * x) #\n","# The loss function, mean squared error, will serve as the negative fitness\n","loss_function = lambda y_true, y_estimate : np.mean((y_true - y_estimate)**2)\n","\n","def simulate_and_evaluate(organism, replicates=1):\n","    \"\"\"\n","    Randomly generate `replicates` samples in [0,1],\n","    use the organism to predict their corresponding value,\n","    and return the fitness score of the organism\n","    \"\"\"\n","    X = np.random.random((replicates, 1))\n","    predictions = organism.predict(X)\n","    loss = loss_function(true_function(X), predictions)\n","    return -loss\n","\n","# Ecosystem requires a function that maps an organism to a real number fitness\n","scoring_function = lambda organism : simulate_and_evaluate(organism, replicates=100)\n","# Create the ecosystem\n","ecosystem = Ecosystem(organism_creator, scoring_function, \n","                      population_size=100, holdout=0.1, mating=True)\n","# Save the fitness score of the best organism in each generation\n","best_organism_scores = [ecosystem.get_best_organism(include_reward=True)[1]]\n","generations = 201\n","for i in range(generations):\n","    ecosystem.generation()\n","    this_generation_best = ecosystem.get_best_organism(include_reward=True)\n","    best_organism_scores.append(this_generation_best[1])\n","    # [Visualization code omitted...]"],"metadata":{"id":"rIu3e65WLUT0","executionInfo":{"status":"ok","timestamp":1675140930914,"user_tz":360,"elapsed":10497,"user":{"displayName":"JAGURA","userId":"01920608359559747946"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Load the data\n","import pandas as pd\n","df = pd.read_csv('iris.csv')\n","# Enumerate the classes\n","unique_classes = sorted(list(set(df['variety'])))\n","class_number = {y : x for x,y in enumerate(unique_classes)}\n","df['variety'] = [class_number[x] for x in df['variety']]\n","# Convert to numpy array and standardize the features\n","data_X = df[['sepal.length', 'sepal.width', 'petal.length', 'petal.width']].values\n","data_Y = df[['variety']].values\n","data_X = data_X - np.min(data_X, axis=0)\n","data_X = data_X / np.max(data_X, axis=0)\n","\n","# The function to create the initial population\n","organism_creator = lambda : Organism([4, 16, 16, 16, 3], output='softmax')\n","# The fitness function will be the classification accuracy\n","fitness_function = lambda y_true, y_estimate : (\n","        np.mean(y_true.flatten() == np.argmax(y_estimate, axis=1)))\n","\n","def simulate_and_evaluate(organism, indices):\n","    \"\"\"\n","    Predict the probabilities of each class and return the fitness\n","    Indices is the list of indices to use in evaluation\n","    \"\"\"\n","    predictions = organism.predict(data_X[indices])\n","    return fitness_function(data_Y[indices], predictions)\n","\n","# Separate training and test data using random indices\n","indices = np.arange(len(df))\n","np.random.shuffle(indices)\n","indices_train, indices_test = indices[:100], indices[100:]\n","\n","# Create the scoring function and build the ecosystem\n","scoring_function = lambda organism : simulate_and_evaluate(organism, indices=indices_train)\n","ecosystem = Ecosystem(organism_creator, scoring_function, \n","                      population_size=100, holdout=0.1, mating=True)\n","                      \n","# Run 20 generations\n","generations = 20\n","for i in range(generations):\n","    ecosystem.generation()\n","    this_generation_best = ecosystem.get_best_organism(include_reward=True)\n","    # [Visualization code omitted...]"],"metadata":{"id":"eikVvtlLLUWa","executionInfo":{"status":"ok","timestamp":1675141216521,"user_tz":360,"elapsed":3996,"user":{"displayName":"JAGURA","userId":"01920608359559747946"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4Jmn1s34NCyf"},"execution_count":null,"outputs":[]}]}